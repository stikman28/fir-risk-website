---
title: "INTEL-2: The Human-in-the-Loop Imperative for AI Security"
description: "NIST built its detection framework around one assumption: AI detects, humans validate. Fully automated security is a design flaw."
date: 2026-02-04
type: "intel"
intel_type: "TREND"
image: "/images/intel/intel-2-human-in-the-loop.png"
tags: ["AI Security", "NIST", "CISO", "MITRE ATT&CK", "SOC"]
---

<img src="/images/intel/intel-2-human-in-the-loop.png" alt="FIR Risk INTEL-2 - Human in the Loop AI Security" class="img-fluid mb-4">

## The INTEL

NIST built its entire detection and response framework around a single assumption: AI detects, humans validate.

Look at the controls:
- **DE.AE-02** — Use automated tools for detection, but prioritize and filter for human review
- **DE.CM-01** — Continuously tune tools to minimize false positives (requires human feedback)
- **RS.MA-02** — Human triage of alerts before escalation

The framework doesn't quantify the benefit. It doesn't need to. The principle is baked into every control: fully automated security is a design flaw, not a feature.

Yet vendors keep selling "autonomous SOCs" and "zero-touch remediation." CISOs are under pressure to automate everything. And attackers are already designing evasion techniques that exploit AI trust.

---

## Why It Matters

Over-automation creates three compounding risks:

1. **AI blind spots** — Models miss context-specific threats like insider activity or novel attack patterns
2. **Adversarial exploitation** — Attackers manipulate AI via data poisoning and model evasion (MITRE T1598.002)
3. **Skills erosion** — Analysts lose critical threat-hunting capabilities when they become button-pushers

Regulatory pressure is mounting. NIST AI RMF and GDPR require human accountability for automated decisions. "The model said so" isn't an audit defense.

---

## What To Do

- **Hybrid workflows** — AI detects and scores; humans validate and escalate. Design this into your SOC, not around it.
- **Feedback loops** — Every false positive your analysts flag should retrain your models. Your team makes your AI smarter.

---

## MITRE ATT&CK

| Technique | Name | Relevance |
|-----------|------|-----------|
| T1566 | Phishing | AI-generated phishing evades traditional ML detection |
| T1598 | Phishing for Information | Reconnaissance exploiting automated trust |
| T1598.002 | Spearphishing Attachment | Targeted payloads designed to bypass AI filters |

---

## Learn More

- [NIST CSF 2.0](https://www.nist.gov/cyberframework) — DE.AE-02, DE.CM-01, RS.MA-02
- [NIST SP 800-61r3](https://csrc.nist.gov/publications/detail/sp/800-61/rev-3/final) — Incident Response guidance
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

---

*Powered by [FIR Risk Platform](/platform/) — AI-driven threat intelligence for enterprise risk leaders.*
